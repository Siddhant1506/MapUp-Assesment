{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "030bc253-aa42-40dd-8411-9d51239d0e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1, 6, 5, 4, 8, 7]\n",
      "[2, 1, 4, 3, 5]\n",
      "[40, 30, 20, 10, 70, 60, 50]\n"
     ]
    }
   ],
   "source": [
    "#Question No 1\n",
    "def reverse_by_n(lst: list, n: int) -> list:\n",
    "    result = []\n",
    "    # Iterate through the list in steps of n\n",
    "    for i in range(0, len(lst), n):\n",
    "        # Reverse the elements manually within each chunk\n",
    "        chunk = lst[i:i+n]\n",
    "        reversed_chunk = []\n",
    "        for j in range(len(chunk)-1, -1, -1):\n",
    "            reversed_chunk.append(chunk[j])\n",
    "        result.extend(reversed_chunk)\n",
    "    return result\n",
    "\n",
    "# Test cases\n",
    "print(reverse_by_n([1, 2, 3, 4, 5, 6, 7, 8], 3))  \n",
    "print(reverse_by_n([1, 2, 3, 4, 5], 2))           \n",
    "print(reverse_by_n([10, 20, 30, 40, 50, 60, 70], 4))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cefc08f-0d1d-4e3d-a9ad-48ab344893c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: ['bat', 'car', 'dog'], 4: ['bear'], 5: ['apple'], 8: ['elephant']}\n",
      "{3: ['one', 'two'], 4: ['four'], 5: ['three']}\n"
     ]
    }
   ],
   "source": [
    "#Question No 2\n",
    "def group_by_length(strings: list) -> dict:\n",
    "    length_dict = {}\n",
    "    \n",
    "    # Group strings by their length\n",
    "    for string in strings:\n",
    "        length = len(string)\n",
    "        if length not in length_dict:\n",
    "            length_dict[length] = []\n",
    "        length_dict[length].append(string)\n",
    "    \n",
    "    # Sort dictionary by the keys (length of strings)\n",
    "    sorted_dict = dict(sorted(length_dict.items()))\n",
    "    \n",
    "    return sorted_dict\n",
    "\n",
    "# Test cases\n",
    "print(group_by_length([\"apple\", \"bat\", \"car\", \"elephant\", \"dog\", \"bear\"])) \n",
    "# Output: {3: ['bat', 'car', 'dog'], 4: ['bear'], 5: ['apple'], 8: ['elephant']}\n",
    "\n",
    "print(group_by_length([\"one\", \"two\", \"three\", \"four\"]))  \n",
    "# Output: {3: ['one', 'two'], 4: ['four'], 5: ['three']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12c7baeb-2e5c-4d4f-8575-1e91dd52917b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'road.name': 'Highway 1', 'road.length': 350, 'road.sections[0].id': 1, 'road.sections[0].condition.pavement': 'good', 'road.sections[0].condition.traffic': 'moderate'}\n"
     ]
    }
   ],
   "source": [
    "#Question No 3\n",
    "def flatten_dict(nested_dict: dict, parent_key: str = '', sep: str = '.') -> dict:\n",
    "    flat_dict = {}\n",
    "    \n",
    "    # Recursive helper function\n",
    "    def _flatten(obj, key):\n",
    "        if isinstance(obj, dict):\n",
    "            # If the value is a dictionary, flatten it recursively\n",
    "            for sub_key, value in obj.items():\n",
    "                new_key = f\"{key}{sep}{sub_key}\" if key else sub_key\n",
    "                _flatten(value, new_key)\n",
    "        elif isinstance(obj, list):\n",
    "            for i, item in enumerate(obj):\n",
    "                new_key = f\"{key}[{i}]\"\n",
    "                _flatten(item, new_key)\n",
    "        else:\n",
    "            flat_dict[key] = obj\n",
    "    \n",
    "    # Initialize the recursion with the nested dictionary\n",
    "    _flatten(nested_dict, parent_key)\n",
    "    \n",
    "    return flat_dict\n",
    "\n",
    "# Test case\n",
    "nested_dict = {\n",
    "    \"road\": {\n",
    "        \"name\": \"Highway 1\",\n",
    "        \"length\": 350,\n",
    "        \"sections\": [\n",
    "            {\n",
    "                \"id\": 1,\n",
    "                \"condition\": {\n",
    "                    \"pavement\": \"good\",\n",
    "                    \"traffic\": \"moderate\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(flatten_dict(nested_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "786ed396-5266-49d7-a970-802c2379e2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 2], [1, 2, 1], [2, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "#Question No 4\n",
    "def unique_permutations(nums: list) -> list:\n",
    "    def backtrack(path, remaining, result):\n",
    "        if not remaining:\n",
    "            result.append(path)\n",
    "            return\n",
    "        prev_num = None\n",
    "        for i in range(len(remaining)):\n",
    "            if remaining[i] == prev_num:  # Skip duplicates\n",
    "                continue\n",
    "            prev_num = remaining[i]\n",
    "            backtrack(path + [remaining[i]], remaining[:i] + remaining[i+1:], result)\n",
    "\n",
    "    nums.sort()  # Sort to handle duplicates easily\n",
    "    result = []\n",
    "    backtrack([], nums, result)\n",
    "    return result\n",
    "\n",
    "# Test case\n",
    "input_list = [1, 1, 2]\n",
    "print(unique_permutations(input_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcfbadb0-84f4-463b-9441-d0c0eded50d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['23-08-1994', '08/23/1994', '1994.08.23']\n"
     ]
    }
   ],
   "source": [
    "#Question No 5\n",
    "import re\n",
    "\n",
    "def find_all_dates(text: str) -> list:\n",
    "    # Defining regex patterns for the three date formats\n",
    "    date_patterns = [\n",
    "        r'\\b\\d{2}-\\d{2}-\\d{4}\\b',   # dd-mm-yyyy\n",
    "        r'\\b\\d{2}/\\d{2}/\\d{4}\\b',   # mm/dd/yyyy\n",
    "        r'\\b\\d{4}\\.\\d{2}\\.\\d{2}\\b'  # yyyy.mm.dd\n",
    "    ]\n",
    "    \n",
    "    # Initialize an empty list to store all matches\n",
    "    dates = []\n",
    "    \n",
    "    # For each pattern, find all matches in the text and add them to the dates list\n",
    "    for pattern in date_patterns:\n",
    "        matches = re.findall(pattern, text)\n",
    "        dates.extend(matches)\n",
    "    \n",
    "    return dates\n",
    "\n",
    "# Test case\n",
    "text = \"I was born on 23-08-1994, my friend on 08/23/1994, and another one on 1994.08.23.\"\n",
    "print(find_all_dates(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58db589c-95c8-4056-9ac3-cc42c1c9df36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting polyline\n",
      "  Downloading polyline-2.0.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\gaikwad\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Collecting geopy\n",
      "  Downloading geopy-2.4.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\gaikwad\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\gaikwad\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gaikwad\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\gaikwad\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Collecting geographiclib<3,>=1.52 (from geopy)\n",
      "  Downloading geographiclib-2.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gaikwad\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading polyline-2.0.2-py3-none-any.whl (6.0 kB)\n",
      "Downloading geopy-2.4.1-py3-none-any.whl (125 kB)\n",
      "   ---------------------------------------- 0.0/125.4 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 30.7/125.4 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 30.7/125.4 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 30.7/125.4 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 30.7/125.4 kB ? eta -:--:--\n",
      "   ------------------------- ------------- 81.9/125.4 kB 353.1 kB/s eta 0:00:01\n",
      "   ------------------------- ------------- 81.9/125.4 kB 353.1 kB/s eta 0:00:01\n",
      "   ------------------------- ------------- 81.9/125.4 kB 353.1 kB/s eta 0:00:01\n",
      "   ------------------------- ------------- 81.9/125.4 kB 353.1 kB/s eta 0:00:01\n",
      "   -------------------------------------- 125.4/125.4 kB 283.7 kB/s eta 0:00:00\n",
      "Downloading geographiclib-2.0-py3-none-any.whl (40 kB)\n",
      "   ---------------------------------------- 0.0/40.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 40.3/40.3 kB ? eta 0:00:00\n",
      "Installing collected packages: polyline, geographiclib, geopy\n",
      "Successfully installed geographiclib-2.0 geopy-2.4.1 polyline-2.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install polyline pandas geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e59a1b1-c81a-4098-b9c1-eee835bb24c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   latitude  longitude     distance\n",
      "0  40.63179   -8.65708     0.000000\n",
      "1  40.62855   -8.72272  5565.029613\n",
      "2  40.67543   -8.69942  5566.387782\n",
      "3  40.67736   -8.70706   680.554747\n",
      "4  40.67542   -8.70632   224.333104\n",
      "5  40.67945   -8.70616   447.726534\n"
     ]
    }
   ],
   "source": [
    "#Question No 6\n",
    "import polyline\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Function to decode polyline and compute distances\n",
    "def decode_polyline_to_dataframe(polyline_str: str) -> pd.DataFrame:\n",
    "    # Step 1: Decode polyline string into (latitude, longitude) coordinates\n",
    "    coordinates = polyline.decode(polyline_str)\n",
    "    \n",
    "    # Step 2: Create a DataFrame from coordinates\n",
    "    df = pd.DataFrame(coordinates, columns=['latitude', 'longitude'])\n",
    "    \n",
    "    # Step 3: Initialize distance column with zeros\n",
    "    df['distance'] = 0.0\n",
    "    \n",
    "    # Step 4: Calculate distance between consecutive points using the Haversine formula\n",
    "    for i in range(1, len(df)):\n",
    "        # Get the coordinates of the current point and the previous point\n",
    "        coord1 = (df.at[i-1, 'latitude'], df.at[i-1, 'longitude'])\n",
    "        coord2 = (df.at[i, 'latitude'], df.at[i, 'longitude'])\n",
    "        \n",
    "        # Calculate the distance between them using the geopy.distance.geodesic method\n",
    "        df.at[i, 'distance'] = geodesic(coord1, coord2).meters\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example polyline string\n",
    "polyline_str = 'u{~vFvyys@fSfyK_dHspCaKvn@bKsCeX_@'\n",
    "df = decode_polyline_to_dataframe(polyline_str)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "381d1aca-a197-4326-83c8-cb3cefbdf7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22, 19, 16], [23, 20, 17], [24, 21, 18]]\n"
     ]
    }
   ],
   "source": [
    "#Question No 7\n",
    "import numpy as np\n",
    "\n",
    "def rotate_and_transform(matrix):\n",
    "    n = len(matrix)\n",
    "    \n",
    "    # Step 1: Rotate the matrix by 90 degrees clockwise\n",
    "    rotated_matrix = [list(reversed(col)) for col in zip(*matrix)]\n",
    "    \n",
    "    # Step 2: Transform the matrix\n",
    "    transformed_matrix = np.zeros((n, n), dtype=int)  # To store the final result\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            # Calculate row sum excluding the current element\n",
    "            row_sum = sum(rotated_matrix[i]) - rotated_matrix[i][j]\n",
    "            # Calculate column sum excluding the current element\n",
    "            col_sum = sum(rotated_matrix[k][j] for k in range(n)) - rotated_matrix[i][j]\n",
    "            # Set the element as the sum of row and column excluding itself\n",
    "            transformed_matrix[i][j] = row_sum + col_sum\n",
    "    \n",
    "    return transformed_matrix.tolist()\n",
    "\n",
    "# Test case\n",
    "matrix = [[1, 2, 3],\n",
    "          [4, 5, 6],\n",
    "          [7, 8, 9]]\n",
    "\n",
    "result = rotate_and_transform(matrix)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b19aa4fa-48d8-4730-85b1-4cacfca37e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question No 8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def check_time_completeness(df):\n",
    "    # Step 1: Parse start and end timestamps as datetime objects\n",
    "    df['start_timestamp'] = pd.to_datetime(df['startDay'] + ' ' + df['startTime'])\n",
    "    df['end_timestamp'] = pd.to_datetime(df['endDay'] + ' ' + df['endTime'])\n",
    "    \n",
    "    # Initialize an empty result dictionary to store boolean values\n",
    "    result = {}\n",
    "    \n",
    "    # Step 2: Group by (id, id_2) to check each pair separately\n",
    "    grouped = df.groupby(['id', 'id_2'])\n",
    "    \n",
    "    # Full range of days (Monday to Sunday) and hours (0 to 23)\n",
    "    full_days = set(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
    "    full_hours = set(range(24))\n",
    "    \n",
    "    # Step 3: Iterate over each (id, id_2) pair\n",
    "    for (id_, id_2), group in grouped:\n",
    "        # Track the days of the week and hours that are covered\n",
    "        covered_days = set()\n",
    "        covered_hours = set()\n",
    "        \n",
    "        # Iterate through the time ranges in the group\n",
    "        for _, row in group.iterrows():\n",
    "            start = row['start_timestamp']\n",
    "            end = row['end_timestamp']\n",
    "            \n",
    "            # Ensure the start and end timestamps span the same or consecutive days\n",
    "            current_time = start\n",
    "            while current_time <= end:\n",
    "                covered_days.add(current_time.strftime('%A'))  # Add day of the week (e.g., Monday)\n",
    "                covered_hours.add(current_time.hour)           # Add hour of the day (e.g., 0 for midnight)\n",
    "                current_time += timedelta(hours=1)             # Increment by 1 hour\n",
    "            \n",
    "        # Step 4: Check if the pair covers all days and all hours\n",
    "        days_complete = (covered_days == full_days)\n",
    "        hours_complete = (covered_hours == full_hours)\n",
    "        \n",
    "        # If either days or hours are incomplete, mark as incorrect (True)\n",
    "        result[(id_, id_2)] = not (days_complete and hours_complete)\n",
    "    \n",
    "    # Step 5: Convert result dictionary to a multi-index boolean series\n",
    "    result_series = pd.Series(result)\n",
    "    result_series.index = pd.MultiIndex.from_tuples(result_series.index, names=['id', 'id_2'])\n",
    "    \n",
    "    return result_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da3700e1-0884-43b8-8027-26b94d8736cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id       id_2    \n",
      "1014000  -1          True\n",
      "1014002  -1          True\n",
      "1014003  -1          True\n",
      "1030000  -1          True\n",
      "          1030002    True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Question No 8\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'dataset-1.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define a mapping for the days of the week\n",
    "day_mapping = {'Monday': 0, 'Tuesday': 1, 'Wednesday': 2, 'Thursday': 3, 'Friday': 4, 'Saturday': 5, 'Sunday': 6}\n",
    "\n",
    "# Convert startDay and endDay to their numeric equivalents using the mapping\n",
    "df['startDay_num'] = df['startDay'].map(day_mapping)\n",
    "df['endDay_num'] = df['endDay'].map(day_mapping)\n",
    "\n",
    "# Function to check for completeness of time data\n",
    "def check_full_coverage_without_timestamp(group):\n",
    "    # Check that all 7 days are present (from Monday to Sunday)\n",
    "    days_covered = set(group['startDay_num'].unique()).union(set(group['endDay_num'].unique()))\n",
    "    all_days_present = days_covered == set(range(7))  # Should cover all days from 0 to 6 (Monday to Sunday)\n",
    "    \n",
    "    # Check if the full 24 hours is covered within each day\n",
    "    for day in range(7):\n",
    "        day_entries = group[(group['startDay_num'] <= day) & (group['endDay_num'] >= day)]\n",
    "        if day_entries.empty:\n",
    "            return False\n",
    "        min_start_time = day_entries['startTime'].min()\n",
    "        max_end_time = day_entries['endTime'].max()\n",
    "        if not (min_start_time == '00:00:00' and max_end_time == '23:59:59'):\n",
    "            return False\n",
    "    \n",
    "    return all_days_present\n",
    "\n",
    "# Apply the function to each (id, id_2) pair without timestamp conversion\n",
    "result_without_timestamp = df.groupby(['id', 'id_2']).apply(check_full_coverage_without_timestamp)\n",
    "\n",
    "# Convert the result to a boolean series with a multi-index indicating incorrect timestamps\n",
    "incorrect_timestamps_without_timestamp = ~result_without_timestamp\n",
    "\n",
    "# Display the top results\n",
    "print(incorrect_timestamps_without_timestamp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec62bd0d-6a49-4f04-99ec-d376d6fe3868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
